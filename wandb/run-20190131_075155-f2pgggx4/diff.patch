diff --git a/.gitignore.txt b/.gitignore.txt
index 7815be8..fc8334b 100644
--- a/.gitignore.txt
+++ b/.gitignore.txt
@@ -1,2 +1,3 @@
 torque_estimation/wandb/
-torque_estimation/.vscode
\ No newline at end of file
+torque_estimation/.vscode
+wandb/
diff --git a/ee_force_estimation_7dof_nn.py b/ee_force_estimation_7dof_nn.py
index b6cee58..1056211 100644
--- a/ee_force_estimation_7dof_nn.py
+++ b/ee_force_estimation_7dof_nn.py
@@ -4,8 +4,13 @@ import csv
 import matplotlib.pyplot as plt
 from sklearn import preprocessing
 import time
+import wandb
+import os
 
+wandb_use = True
 start_time = time.time()
+if wandb_use == True:
+    wandb.init(project="dusan_ws", tensorboard=False)
 
 class Model:
 
@@ -25,39 +30,35 @@ class Model:
             # weights & bias for nn layers
             # http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow
             W1 = tf.get_variable("W1", shape=[num_input, 10], initializer=tf.contrib.layers.xavier_initializer())
-            b1 = tf.Variable(tf.random_normal([10]))
+            b1 = tf.Variable(tf.random_normal([10]), name='b1')
             L1 = tf.matmul(self.X, W1) +b1
-            #L1 = tf.layers.batch_normalization(L1, center=True, scale=True, training=1)
-            L1 = tf.nn.relu(L1)
-            #L1 = tf.nn.sigmoid(tf.matmul(self.X, W1) + b1)
+            #L1 = tf.nn.relu(L1)
+            L1 = tf.nn.sigmoid(L1)
             L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)
 
             W2 = tf.get_variable("W2", shape=[10, 10], initializer=tf.contrib.layers.xavier_initializer())
-            b2 = tf.Variable(tf.random_normal([10]))
+            b2 = tf.Variable(tf.random_normal([10]), name='b2')
             L2 = tf.matmul(L1, W2) +b2
-            #L2 = tf.layers.batch_normalization(L2, center=True, scale=True, training=1)
-            L2 = tf.nn.relu(L2)
-            #L2 = tf.nn.sigmoid(tf.matmul(L1, W2) + b2)
+            #L2 = tf.nn.relu(L2)
+            L2 = tf.nn.sigmoid(L2)
             L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)
 
             W3 = tf.get_variable("W3", shape=[10, 10], initializer=tf.contrib.layers.xavier_initializer())
-            b3 = tf.Variable(tf.random_normal([10]))
+            b3 = tf.Variable(tf.random_normal([10]), name='b3')
             L3 = tf.matmul(L2, W3) +b3
-            #L3 = tf.layers.batch_normalization(L3, center=True, scale=True, training=1)
-            L3 = tf.nn.relu(L3)
-            #L3 = tf.nn.relu(tf.sigmoid(L2, W3) + b3)
+            #L3 = tf.nn.relu(L3)
+            L3 = tf.nn.sigmoid(L3)
             L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)
 
             W4 = tf.get_variable("W4", shape=[10, 10], initializer=tf.contrib.layers.xavier_initializer())
-            b4 = tf.Variable(tf.random_normal([10]))
+            b4 = tf.Variable(tf.random_normal([10]), name='b4')
             L4 = tf.matmul(L3, W4) +b4
-            #L4 = tf.layers.batch_normalization(L4, center=True, scale=True, training=1)
-            L4 = tf.nn.relu(L4)
-            #L4 = tf.nn.relu(tf.sigmoid(L3, W4) + b4)
+            #L4 = tf.nn.relu(L4)
+            L4 = tf.nn.sigmoid(L4)
             L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)
 
-            W5 = tf.get_variable("W6", shape=[10, num_output], initializer=tf.contrib.layers.xavier_initializer())
-            b5 = tf.Variable(tf.random_normal([num_output]))
+            W5 = tf.get_variable("W5", shape=[10, num_output], initializer=tf.contrib.layers.xavier_initializer())
+            b5 = tf.Variable(tf.random_normal([num_output]), name='b5')
             self.hypothesis = tf.matmul(L4, W5) + b5
             self.hypothesis = tf.identity(self.hypothesis, "hypothesis")
 
@@ -109,7 +110,6 @@ for line in rdr:
 
 t = np.reshape(t,(-1,1))
 x_data_test = np.reshape(x_data_test, (-1, num_input))
-#x_data_test = preprocessing.scale(x_data_test)
 y_data_test = np.reshape(y_data_test, (-1, num_output))
 
 # load validation data
@@ -123,17 +123,23 @@ for line in rdr:
     y_data_val.append(line[-num_output:])
     #y_data_val.append(line[-output_idx])
 x_data_val = np.reshape(x_data_val, (-1, num_input))
-#x_data_val = preprocessing.scale(x_data_val)
 y_data_val = np.reshape(y_data_val, (-1, num_output))
 
 # parameters
 learning_rate = 0.005
-training_epochs = 1000
+training_epochs = 2000
 batch_size = 100
 total_batch = int(np.shape(x_data_test)[0]/batch_size*5)
 drop_out = 1.0
 
-
+if wandb_use == True:
+    wandb.config.epoch = training_epochs
+    wandb.config.batch_size = batch_size
+    wandb.config.learning_rate = learning_rate
+    wandb.config.drop_out = drop_out
+    wandb.config.num_input = num_input
+    wandb.config.num_output = num_output
+    wandb.config.activation_function = "Sigmoid"
 
 # initialize
 sess = tf.Session()
@@ -151,7 +157,6 @@ for epoch in range(training_epochs):
 
     for i in range(total_batch):
         batch_xs, batch_ys = m1.next_batch(batch_size, rdr)
-        #batch_xs = preprocessing.scale(batch_xs)
         c, _ = m1.train(batch_xs, batch_ys, drop_out)
         avg_cost += c / total_batch
 
@@ -163,6 +168,14 @@ for epoch in range(training_epochs):
     train_mse[epoch] = avg_cost
     validation_mse[epoch] = cost
 
+    if wandb_use == True:
+        wandb.log({'training cost': avg_cost, 'validation cost': cost})
+
+        if epoch % 20 ==0:
+            for var in tf.trainable_variables():
+                name = var.name
+                wandb.log({name: sess.run(var)})
+
 print('Learning Finished!')
 
 
@@ -170,12 +183,18 @@ print('Learning Finished!')
 # print('Error: ', error,"\n x_data: ", x_test,"\nHypothesis: ", hypo, "\n y_data: ", y_test)
 print('Test Error: ', error)
 
-saver = tf.train.Saver()
-saver.save(sess,'model/model.ckpt')
 
 elapsed_time = time.time() - start_time
 print(elapsed_time)
 
+
+saver = tf.train.Saver()
+saver.save(sess,'model/model.ckpt')
+
+if wandb_use == True:
+    wandb.save(os.path.join(wandb.run.dir, 'model/model.ckpt'))
+    wandb.config.elapsed_time = elapsed_time
+
 epoch = np.arange(training_epochs)
 plt.plot(epoch, train_mse, 'r', label='train')
 plt.plot(epoch, validation_mse, 'b', label='validation')
diff --git a/ee_force_estimation_7dof_result.py b/ee_force_estimation_7dof_result.py
index 4f7bfc6..d67abc0 100644
--- a/ee_force_estimation_7dof_result.py
+++ b/ee_force_estimation_7dof_result.py
@@ -7,6 +7,7 @@ from sklearn import preprocessing
 # parameters
 num_input = 28
 num_output = 6
+output_idx = 6
 
 # raw data
 f = open('raw_data_.csv', 'r', encoding='utf-8')
@@ -20,10 +21,10 @@ for line in rdr:
     t.append(line[0])
     x_data_raw.append(line[1:num_input+1])
     y_data_raw.append(line[-num_output:])
+    #y_data_raw.append(line[-output_idx])
 
 t = np.reshape(t,(-1,1))
 x_data_raw = np.reshape(x_data_raw, (-1, num_input))
-#x_data_raw = preprocessing.scale(x_data_raw)
 y_data_raw = np.reshape(y_data_raw, (-1, num_output))
 
 tf.reset_default_graph()
@@ -46,6 +47,14 @@ mean_error = np.mean(np.abs(y_data_raw[:,res_idx]-hypo[:,res_idx]))
 print("Mean error : %f" % mean_error)
  
 
+# plt.plot(t,y_data_raw[:,res_idx], 'r', label='real')
+# plt.plot(t,hypo[:,res_idx], 'b', label='prediction')
+# plt.xlabel('time')
+# plt.ylabel('Fx')
+# plt.legend()
+# plt.show()
+
+
 plt.subplot(3,1,1)
 plt.plot(t,y_data_raw[:,res_idx], 'r', label='real')
 plt.plot(t,hypo[:,res_idx], 'b', label='prediction')
diff --git a/model/model.ckpt.data-00000-of-00001 b/model/model.ckpt.data-00000-of-00001
index b0e4368..c484444 100644
Binary files a/model/model.ckpt.data-00000-of-00001 and b/model/model.ckpt.data-00000-of-00001 differ
diff --git a/model/model.ckpt.index b/model/model.ckpt.index
index fd32bbe..baeb28a 100644
Binary files a/model/model.ckpt.index and b/model/model.ckpt.index differ
diff --git a/model/model.ckpt.meta b/model/model.ckpt.meta
index c726684..70f234d 100644
Binary files a/model/model.ckpt.meta and b/model/model.ckpt.meta differ
diff --git a/model_backup/model_10955/checkpoint b/model_backup/model_10955/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_10955/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_10955/model.ckpt.data-00000-of-00001 b/model_backup/model_10955/model.ckpt.data-00000-of-00001
deleted file mode 100644
index 4e01c63..0000000
Binary files a/model_backup/model_10955/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_10955/model.ckpt.index b/model_backup/model_10955/model.ckpt.index
deleted file mode 100644
index 264a6f0..0000000
Binary files a/model_backup/model_10955/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_10955/model.ckpt.meta b/model_backup/model_10955/model.ckpt.meta
deleted file mode 100644
index 2af2e64..0000000
Binary files a/model_backup/model_10955/model.ckpt.meta and /dev/null differ
diff --git a/model_backup/model_10955_dropout_0.8/checkpoint b/model_backup/model_10955_dropout_0.8/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_10955_dropout_0.8/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_10955_dropout_0.8/model.ckpt.data-00000-of-00001 b/model_backup/model_10955_dropout_0.8/model.ckpt.data-00000-of-00001
deleted file mode 100644
index 9aa8ef2..0000000
Binary files a/model_backup/model_10955_dropout_0.8/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_10955_dropout_0.8/model.ckpt.index b/model_backup/model_10955_dropout_0.8/model.ckpt.index
deleted file mode 100644
index 888a8a3..0000000
Binary files a/model_backup/model_10955_dropout_0.8/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_10955_dropout_0.8/model.ckpt.meta b/model_backup/model_10955_dropout_0.8/model.ckpt.meta
deleted file mode 100644
index 2af2e64..0000000
Binary files a/model_backup/model_10955_dropout_0.8/model.ckpt.meta and /dev/null differ
diff --git a/model_backup/model_17310/checkpoint b/model_backup/model_17310/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_17310/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_17310/model.ckpt.data-00000-of-00001 b/model_backup/model_17310/model.ckpt.data-00000-of-00001
deleted file mode 100644
index 244e36e..0000000
Binary files a/model_backup/model_17310/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_17310/model.ckpt.index b/model_backup/model_17310/model.ckpt.index
deleted file mode 100644
index c9936c0..0000000
Binary files a/model_backup/model_17310/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_17310/model.ckpt.meta b/model_backup/model_17310/model.ckpt.meta
deleted file mode 100644
index 7ef35cd..0000000
Binary files a/model_backup/model_17310/model.ckpt.meta and /dev/null differ
diff --git a/model_backup/model_17310_2nd/checkpoint b/model_backup/model_17310_2nd/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_17310_2nd/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_17310_2nd/model.ckpt.data-00000-of-00001 b/model_backup/model_17310_2nd/model.ckpt.data-00000-of-00001
deleted file mode 100644
index 71146f0..0000000
Binary files a/model_backup/model_17310_2nd/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_17310_2nd/model.ckpt.index b/model_backup/model_17310_2nd/model.ckpt.index
deleted file mode 100644
index 0f3ec40..0000000
Binary files a/model_backup/model_17310_2nd/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_17310_2nd/model.ckpt.meta b/model_backup/model_17310_2nd/model.ckpt.meta
deleted file mode 100644
index 891c098..0000000
Binary files a/model_backup/model_17310_2nd/model.ckpt.meta and /dev/null differ
diff --git a/model_backup/model_5790/checkpoint b/model_backup/model_5790/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_5790/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_5790/model.ckpt.data-00000-of-00001 b/model_backup/model_5790/model.ckpt.data-00000-of-00001
deleted file mode 100644
index 47c49b3..0000000
Binary files a/model_backup/model_5790/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_5790/model.ckpt.index b/model_backup/model_5790/model.ckpt.index
deleted file mode 100644
index 6b09473..0000000
Binary files a/model_backup/model_5790/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_5790/model.ckpt.meta b/model_backup/model_5790/model.ckpt.meta
deleted file mode 100644
index 7ef35cd..0000000
Binary files a/model_backup/model_5790/model.ckpt.meta and /dev/null differ
diff --git a/model_backup/model_final_20_epi/checkpoint b/model_backup/model_final_20_epi/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_final_20_epi/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_final_20_epi/model.ckpt.data-00000-of-00001 b/model_backup/model_final_20_epi/model.ckpt.data-00000-of-00001
deleted file mode 100644
index c5b1f2c..0000000
Binary files a/model_backup/model_final_20_epi/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_final_20_epi/model.ckpt.index b/model_backup/model_final_20_epi/model.ckpt.index
deleted file mode 100644
index 1a0186b..0000000
Binary files a/model_backup/model_final_20_epi/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_final_20_epi/model.ckpt.meta b/model_backup/model_final_20_epi/model.ckpt.meta
deleted file mode 100644
index 11362e7..0000000
Binary files a/model_backup/model_final_20_epi/model.ckpt.meta and /dev/null differ
diff --git a/model_backup/model_final_50_epi/checkpoint b/model_backup/model_final_50_epi/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_final_50_epi/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_final_50_epi/model.ckpt.data-00000-of-00001 b/model_backup/model_final_50_epi/model.ckpt.data-00000-of-00001
deleted file mode 100644
index 5469848..0000000
Binary files a/model_backup/model_final_50_epi/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_final_50_epi/model.ckpt.index b/model_backup/model_final_50_epi/model.ckpt.index
deleted file mode 100644
index 662e866..0000000
Binary files a/model_backup/model_final_50_epi/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_final_50_epi/model.ckpt.meta b/model_backup/model_final_50_epi/model.ckpt.meta
deleted file mode 100644
index d8a6364..0000000
Binary files a/model_backup/model_final_50_epi/model.ckpt.meta and /dev/null differ
diff --git a/model_backup/model_qddot_7180/checkpoint b/model_backup/model_qddot_7180/checkpoint
deleted file mode 100644
index febd7d5..0000000
--- a/model_backup/model_qddot_7180/checkpoint
+++ /dev/null
@@ -1,2 +0,0 @@
-model_checkpoint_path: "model.ckpt"
-all_model_checkpoint_paths: "model.ckpt"
diff --git a/model_backup/model_qddot_7180/model.ckpt.data-00000-of-00001 b/model_backup/model_qddot_7180/model.ckpt.data-00000-of-00001
deleted file mode 100644
index 596dc8e..0000000
Binary files a/model_backup/model_qddot_7180/model.ckpt.data-00000-of-00001 and /dev/null differ
diff --git a/model_backup/model_qddot_7180/model.ckpt.index b/model_backup/model_qddot_7180/model.ckpt.index
deleted file mode 100644
index 3fc6d72..0000000
Binary files a/model_backup/model_qddot_7180/model.ckpt.index and /dev/null differ
diff --git a/model_backup/model_qddot_7180/model.ckpt.meta b/model_backup/model_qddot_7180/model.ckpt.meta
deleted file mode 100644
index 2af2e64..0000000
Binary files a/model_backup/model_qddot_7180/model.ckpt.meta and /dev/null differ
